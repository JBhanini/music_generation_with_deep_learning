import numpy as np
from music21 import instrument, note, stream, chord
from cnn_preprocessing import unique_x,x_val,no_of_timesteps
from transcribe import transcribe_cnn_sheet

#Instead of recreating the model, i use Keras to load it directly
from keras.models import load_model
model = load_model('medium-350-cnn-model.hdf5')


#Making predictions
ind = np.random.randint(0, len(x_val) - 1)


def predictions():
    random_music = x_val[ind]

    predictions = []
    for i in range(150):


        random_music = random_music.reshape(1,no_of_timesteps)

        prob = model.predict(random_music)[0]
        y_pred = np.argmax(prob, axis=0)
        predictions.append(y_pred)

        random_music = np.insert(random_music[0], len(random_music[0]), y_pred)
        random_music = random_music[1:]
    return predictions


def mapping():
    # Mapping integers back to notes
    x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x))
    predicted_notes = [x_int_to_note[i] for i in predictions()]
    return predicted_notes


def convert_to_midi(prediction_output):
    # converting the generated integers to a midi file
    offset = 0
    output_notes = []

    # create note and chord objects based on the values generated by the model
    for pattern in prediction_output:

        # pattern is a chord
        if ('.' in pattern) or pattern.isdigit():
            notes_in_chord = pattern.split('.')
            notes = []

            for current_note in notes_in_chord:

                cn = int(current_note)
                new_note = note.Note(cn)
                new_note.storedInstrument = instrument.Piano()
                notes.append(new_note)

            new_chord = chord.Chord(notes)
            new_chord.offset = offset
            output_notes.append(new_chord)

        # pattern is a note
        else:

            new_note = note.Note(pattern)
            new_note.offset = offset
            new_note.storedInstrument = instrument.Piano()
            output_notes.append(new_note)

        # increase offset each iteration so that notes do not stack
        offset += 1
    midi_stream = stream.Stream(output_notes)
    midi_stream.write('midi', fp='cnn_generated.mid')


def cnn_generate():
    convert_to_midi(mapping())
    transcribe_cnn_sheet('cnn_generated.mid')